{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机抽样取件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 策略\n",
    "\n",
    "1. 根据票件的5种类型，对着五种类型的包裹按比例提取，以parcel_id为主  \n",
    "2. 最后把五种包裹合并  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 连接数据库，读取包裹信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\pymysql\\cursors.py:165: Warning: (1366, \"Incorrect string value: '\\\\xD6\\\\xD0\\\\xB9\\\\xFA\\\\xB1\\\\xEA...' for column 'VARIABLE_VALUE' at row 480\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Table i_od_parcel_2025v31_plus_mix_pct1 not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_sql_table\u001b[1;34m(table_name, con, schema, index_col, coerce_float, parse_dates, columns, chunksize)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mmeta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreflect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0monly\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mviews\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0msqlalchemy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidRequestError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\sqlalchemy\\sql\\schema.py\u001b[0m in \u001b[0;36mreflect\u001b[1;34m(self, bind, schema, views, only, extend_existing, autoload_replace, **dialect_kwargs)\u001b[0m\n\u001b[0;32m   3903\u001b[0m                         \u001b[1;34m'in %r%s: (%s)'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3904\u001b[1;33m                         (bind.engine, s, ', '.join(missing)))\n\u001b[0m\u001b[0;32m   3905\u001b[0m                 load = [name for name in only if extend_existing or\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: Could not reflect: requested table(s) not available in Engine(mysql+pymysql://root:***@localhost/TEST?charset=utf8): (i_od_parcel_2025v31_plus_mix_pct1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-168fe904b534>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mdb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     host=host))\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mod_parcel_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_table\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_sql_table\u001b[1;34m(table_name, con, schema, index_col, coerce_float, parse_dates, columns, chunksize)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[0mmeta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreflect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0monly\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mviews\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0msqlalchemy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidRequestError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Table %s not found\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtable_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[0mpandas_sql\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSQLDatabase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Table i_od_parcel_2025v31_plus_mix_pct1 not found"
     ]
    }
   ],
   "source": [
    "# 数据库连接参数\n",
    "u_name = \"root\"\n",
    "pwd  = \"root123\"\n",
    "db = \"TEST\"\n",
    "host = \"localhost\"\n",
    "\n",
    "# 读取数据库表名\n",
    "read_table = \"i_od_parcel_2025v31_mix_test\"\n",
    "# 写入的数据库表名\n",
    "write_table = 'i_od_parcel_2025v31_mix_pct1_test'\n",
    "\n",
    "# 创建连接引擎\n",
    "engine = create_engine('mysql+pymysql://{u_name}:'\n",
    "                       '{pwd}@{host}/{db}'\n",
    "                       '?charset=utf8'.format(\n",
    "    u_name=u_name,\n",
    "    pwd=pwd,\n",
    "    db=db,\n",
    "    host=host))\n",
    "old_parcel_df = pd.read_sql_table(read_table,con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 抽样预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抽样比例 : 抽样除数\n",
    "sample_rate = {\n",
    "    '1%':100,\n",
    "    '10%':10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有irregular类型的parcel_id\n",
    "irregular_parcel_id_list =\n",
    "    list(old_parcel_df.loc[old_parcel_df.parcel_type.isin([\"irregular\"]),[\"parcel_id\"]].parcel_id.unique())\n",
    "\n",
    "# 所有isb类型的parcel_id\n",
    "isb_parcel_id_list = \n",
    "    list(d_parcel.loc[old_parcel_df.parcel_type.isin([\"isb\"]),[\"parcel_id\"]].parcel_id.unique())\n",
    "\n",
    "# 所有nc类型的parcel_id\n",
    "nc_parcel_id_list = \n",
    "    list(d_parcel.loc[old_parcel_df.parcel_type.isin([\"nc\"]),[\"parcel_id\"]].parcel_id.unique())\n",
    "\n",
    "# 所有parcel类型的parcel_id\n",
    "parcle_parcel_id_list = \n",
    "    list(d_parcel.loc[old_parcel_df.parcel_type.isin([\"parcel\"]),[\"parcel_id\"]].parcel_id.unique())\n",
    "\n",
    "# 所有small类型的parcel_id\n",
    "small_parcel_id_list = \n",
    "    list(d_parcel.loc[old_parcel_df.parcel_type.isin([\"small\"]),[\"parcel_id\"]].parcel_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_parcel_df1 = old_parcel_df.loc[:,['small_id','parcel_id','parcel_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 长度\n",
    "len(old_parcel_df1.loc[old_parcel_df1.parcel_type.isin(['small']),'small_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = old_parcel_df1.groupby('parcel_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算出各种类型非重复的数量\n",
    "type_dict = a.parcel_id.nunique().to_dict()   # 查看去重后的数量\n",
    "type_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 源数据 parcel_type: [parcel_id]\n",
    "old_type_dict = {\n",
    "    'irregular': irregular_small_id_list,\n",
    "    'isb': isb_small_id_list, \n",
    "    'nc': nc_small_id_list, \n",
    "    'parcel': parcle_small_id_list,\n",
    "    'small': small_small_id_list}\n",
    "\n",
    "\n",
    "irregular_list=[]\n",
    "isb_list=[]\n",
    "nc_list=[]\n",
    "parcel_list=[]\n",
    "small_list=[]\n",
    "\n",
    "# 抽样后的 parcel_type：[parcel_id]\n",
    "sample_type_dict={\n",
    "    'irregular': irregular_list, \n",
    "    'isb': isb_list, \n",
    "    'nc': nc_list, \n",
    "    'parcel': parcel_list, \n",
    "    'small': small_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_random(divisor):\n",
    "    ''' \n",
    "    抽样函数：传入抽样的 divisor 值，返回抽样完成的 sample_type_dict\n",
    "    '''\n",
    "    for k,val in type_dict.items():\n",
    "        \n",
    "        while True:\n",
    "            if len(set(old_type_dict[k])) == round(val/divisor):\n",
    "                break\n",
    "            parcel_id = random.choice(old_type_dict[k])\n",
    "            sample_type_dict[k].append(parcel_id)\n",
    "    return sample_type_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 抽样%1，并存储数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_type_dict = sample_random(sample_rate['1%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连接列表数据\n",
    "parcel_li = irregular_list + isb_list + nc_list + parcel_list + small_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(parcel_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出抽样的数据，存入新的df中\n",
    "new_parcel_df = old_parcel_df.loc[old_parcel_df.parcel_id.isin(parcel_li),:]\n",
    "new_parcel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存入数据库中\n",
    "parcel_1.to_sql(write_table,engine,if_exists='append',chunksize=10000,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
